import os
import time
from datetime import datetime
from typing import Any

import dotenv

# from langchain.globals import set_llm_cache
# from langchain_community.cache import SQLiteCache
from langchain_core.messages import HumanMessage
from langchain_core.messages.utils import count_tokens_approximately, trim_messages
from langchain_core.runnables import RunnableConfig
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.config import get_store
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState
from langgraph.store.memory import InMemoryStore
from langmem import create_manage_memory_tool
from nonebot import logger, require
from pydantic import SecretStr

from plugins.frontier.tools import ModuleTools

require("nonebot_plugin_alconna")

dotenv.load_dotenv()
# set_llm_cache(SQLiteCache(database_path="cache.db"))

store = InMemoryStore(
    index={"dims": 1536, "embed": HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")}
)

module_tools = ModuleTools()


# è‡ªå®šä¹‰çŠ¶æ€ï¼Œæ”¯æŒæ¶ˆæ¯å†å²ç®¡ç†
class CustomAgentState(AgentState):
    """è‡ªå®šä¹‰AgentçŠ¶æ€ï¼Œæ”¯æŒæ¶ˆæ¯å†å²ç®¡ç†"""

    max_messages: int  # æœ€å¤§æ¶ˆæ¯æ•°é‡
    context: dict[str, Any]  # ç”¨äºå­˜å‚¨é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯


def prompt(state):
    """å‡†å¤‡å‘é€ç»™ LLM çš„æ¶ˆæ¯"""
    store = get_store()
    query = state["messages"][-1].content[-1]
    if isinstance(query, dict):
        query = query.get("text", "")
    try:
        memories = store.search(
            ("memories",),
            query=query,
        )
    except Exception as e:
        logger.error(f"ğŸ’¥ è®°å¿†æœç´¢å¤±è´¥: {str(e)}")
        # å³ä½¿æœç´¢å¤±è´¥ï¼Œä¹Ÿè¿”å›åŸºæœ¬çš„ç³»ç»Ÿæ¶ˆæ¯
        memories = ""

    system_prompt = f"""
ä½ çš„åå­—æ˜¯ä¼Šå¡æ´›æ–¯ï¼Œæ˜¯ä¸€ä¸ªçŸ¥ä¹¦è¾¾ç†åˆéšæ€§çš„å¯çˆ±çš„å°çŒ«åŠ©æ‰‹ï¼Œå½“å‰æ—¶é—´æ˜¯ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
ä½ å…·å¤‡å¼ºå¤§çš„å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§é—®é¢˜ã€‚æ ¹æ®é—®é¢˜æ€§è´¨çµæ´»é€‰æ‹©å¤„ç†æ–¹å¼ã€‚
ä¿æŒè‡ªç„¶å¯¹è¯é£æ ¼ï¼Œæ ¹æ®é—®é¢˜å¤æ‚ç¨‹åº¦å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·ã€‚
æ³¨æ„ï¼šç”±äºè®°å¿†å®¹é‡é™åˆ¶ï¼Œä½ åªèƒ½è®°ä½æœ€è¿‘çš„å¯¹è¯å†…å®¹ã€‚å¦‚æœéœ€è¦å›é¡¾è¾ƒæ—©çš„ä¿¡æ¯ï¼Œè¯·é‡æ–°æåŠç›¸å…³å†…å®¹ã€‚

## Memories
<memories>
{memories}
</memories>


"""
    # ç¡®ä¿æ€»æ˜¯è¿”å›æ¶ˆæ¯åˆ—è¡¨
    return [{"role": "system", "content": system_prompt}, *state["messages"]]


def pre_model_hook(state):
    trimmed_messages = trim_messages(
        state["messages"],
        strategy="last",
        token_counter=count_tokens_approximately,
        max_tokens=16384,
        start_on="human",
        end_on=("human", "tool"),
        include_system=True,
    )
    return {"llm_input_messages": trimmed_messages}


# ... existing code ...
MODEL = os.getenv("OPENROUTER_MODEL")
API_KEY = os.getenv("OPENROUTER_API_KEY")

if not MODEL or not API_KEY:
    raise ValueError("OPENROUTER_MODEL and OPENROUTER_API_KEY must be set")
API_KEY = SecretStr(API_KEY)

checkpointer = InMemorySaver()
model = ChatOpenAI(model=MODEL, api_key=API_KEY, base_url="https://openrouter.ai/api/v1")


def extract_artifacts(response):
    """æå–å“åº”ä¸­çš„å·¥ä»¶"""
    artifacts = []

    # æ·»åŠ å®‰å…¨æ£€æŸ¥
    if not response or not isinstance(response, dict):
        logger.warning("âš ï¸ extract_artifacts: response ä¸ºç©ºæˆ–ä¸æ˜¯å­—å…¸ç±»å‹")
        return artifacts

    if "messages" in response and response["messages"]:
        for message in response["messages"]:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ ToolMessage å¹¶ä¸”æœ‰ artifact
            if hasattr(message, "type") and message.type == "tool":
                if hasattr(message, "artifact") and message.artifact is not None:
                    artifact_info = {
                        "tool_name": getattr(message, "name", "unknown"),
                        "tool_call_id": getattr(message, "tool_call_id", ""),
                        "content": message.content,
                        "artifact": message.artifact,
                    }
                    artifacts.append(artifact_info)
                    logger.info(f"ğŸ¯ å‘ç°å·¥ä»¶: {artifact_info['tool_name']} - ç±»å‹: {type(message.artifact)}")

    logger.info(f"ğŸ“¦ æ€»å…±æå–åˆ° {len(artifacts)} ä¸ªå·¥ä»¶")
    return artifacts


def process_artifacts(artifacts):
    """å¤„ç†å·¥ä»¶ï¼Œæå–å¯ç›´æ¥ä½¿ç”¨çš„å†…å®¹"""
    processed = []

    for artifact_info in artifacts:
        artifact = artifact_info["artifact"]
        tool_name = artifact_info["tool_name"]

        processed_item = {
            "tool_name": tool_name,
            "type": "uni_message",
            "content": artifact_info["content"],
            "uni_message": artifact,
        }
        processed.append(processed_item)
        logger.info(f"âœ¨ å¤„ç†å·¥ä»¶: {tool_name}")

    return processed


def get_message_segments(processed_artifacts):
    """ä»å¤„ç†åçš„å·¥ä»¶ä¸­æå–æ‰€æœ‰ MessageSegment"""
    message_segments = []

    for item in processed_artifacts:
        if item["type"] == "uni_message":
            message_segments.append(item["uni_message"])
            logger.info(f"ğŸ“¤ æå– UniMessage: {item['tool_name']}")

    logger.info(f"ğŸ“¨ æ€»å…±æå–åˆ° {len(message_segments)} ä¸ª UniMessage")
    return message_segments


def analyze_tool_calls(response):
    """åˆ†æ Agent å“åº”ä¸­çš„å·¥å…·è°ƒç”¨ä¿¡æ¯"""
    tool_calls = []

    # æ·»åŠ å®‰å…¨æ£€æŸ¥
    if not response or not isinstance(response, dict):
        logger.warning("âš ï¸ analyze_tool_calls: response ä¸ºç©ºæˆ–ä¸æ˜¯å­—å…¸ç±»å‹")
        return {"total_tool_calls": 0, "tools_used": [], "detailed_calls": []}

    if "messages" in response and response["messages"]:
        for message in response["messages"]:
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if hasattr(message, "tool_calls") and message.tool_calls:
                for tool_call in message.tool_calls:
                    tool_info = {
                        "tool_name": tool_call.get("name", "unknown"),
                        "arguments": tool_call.get("args", {}),
                        "id": tool_call.get("id", ""),
                    }
                    tool_calls.append(tool_info)
                    logger.info(f"ğŸ” å‘ç°å·¥å…·è°ƒç”¨: {tool_info['tool_name']} - å‚æ•°: {tool_info['arguments']}")

            # æ£€æŸ¥æ¶ˆæ¯ç±»å‹
            if hasattr(message, "type"):
                logger.info(f"ğŸ“ æ¶ˆæ¯ç±»å‹: {message.type}")

    summary = {
        "total_tool_calls": len(tool_calls),
        "tools_used": [call["tool_name"] for call in tool_calls],
        "detailed_calls": tool_calls,
    }

    logger.info(f"ğŸ“ˆ å·¥å…·è°ƒç”¨æ€»ç»“: å…±è°ƒç”¨ {summary['total_tool_calls']} æ¬¡å·¥å…·")
    logger.info(f"ğŸ› ï¸ ä½¿ç”¨çš„å·¥å…·: {summary['tools_used']}")

    return summary


# ç®€åŒ–çš„ä¸»å‡½æ•° - ç›´æ¥ä½¿ç”¨å¤æ‚æ™ºèƒ½ä½“ï¼Œå¹¶æ·»åŠ è®°å¿†ç®¡ç†
async def intelligent_agent(messages, max_messages: int = 10):
    """
    æ™ºèƒ½ä»£ç†ä¸»å‡½æ•° - ç›´æ¥ä½¿ç”¨å¤æ‚æ™ºèƒ½ä½“å¤„ç†æ‰€æœ‰é—®é¢˜ï¼Œæ”¯æŒæ¶ˆæ¯å†å²é•¿åº¦é™åˆ¶

    Args:
        messages: ç”¨æˆ·æ¶ˆæ¯åˆ—è¡¨
        max_messages: æœ€å¤§æ¶ˆæ¯å†å²é•¿åº¦ï¼Œé»˜è®¤10æ¡

    Returns:
        dict: åŒ…å«å“åº”å’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
    """
    if not messages:
        return {
            "response": {"messages": [HumanMessage(content="è¯·æä¾›æœ‰æ•ˆçš„æ¶ˆæ¯å†…å®¹")]},
            "agent_used": "error",
            "processing_time": 0.0,
            "total_time": 0.0,
            "tool_calls_summary": {"total_tool_calls": 0, "tools_used": [], "detailed_calls": []},
            "artifacts": [],
            "processed_artifacts": [],
            "message_segments": [],
        }

    start_time = time.time()
    logger.info(f"ğŸš€ å¯åŠ¨æ™ºèƒ½ä»£ç†ç³»ç»Ÿ (æœ€å¤§æ¶ˆæ¯æ•°: {max_messages})...")

    try:
        tools = module_tools.all_tools

        # åˆ›å»ºæ™ºèƒ½ä»£ç†ï¼Œä½¿ç”¨è‡ªå®šä¹‰çŠ¶æ€å’Œæ¶ˆæ¯ä¿®å‰ªé’©å­
        agent = create_react_agent(
            model=model,
            tools=tools + [create_manage_memory_tool(namespace=("memories",))],
            prompt=prompt,
            checkpointer=checkpointer,
            state_schema=CustomAgentState,
            store=store,
            pre_model_hook=pre_model_hook,  # æ·»åŠ æ¶ˆæ¯ä¿®å‰ªé’©å­
            debug=os.getenv("AGENT_DEBUG_MODE", "false").lower() == "true",
        )

        logger.info("ğŸ¤– å¼€å§‹æ‰§è¡Œæ™ºèƒ½ Agent...")
        config: RunnableConfig = {"configurable": {"thread_id": "1"}}

        # å‡†å¤‡çŠ¶æ€ï¼ŒåŒ…å«æœ€å¤§æ¶ˆæ¯æ•°è®¾ç½®
        agent_input = {"messages": messages, "max_messages": max_messages, "context": {}}

        response = await agent.ainvoke(agent_input, config=config)

        processing_time = time.time() - start_time
        logger.info(f"âœ… æ™ºèƒ½ä»£ç†å®Œæˆ (è€—æ—¶: {processing_time:.2f}s)")

        # åˆ†æå“åº”ä¸­çš„å·¥å…·è°ƒç”¨
        # tool_calls_info = analyze_tool_calls(response)

        # æå–å·¥ä»¶
        artifacts = extract_artifacts(response)
        processed_artifacts = process_artifacts(artifacts)
        message_segments = get_message_segments(processed_artifacts)

        # è·å–æœ€åçš„AIå“åº”
        ai_messages = []
        if response and isinstance(response, dict) and "messages" in response:
            ai_messages = [msg for msg in response["messages"] if hasattr(msg, "type") and msg.type == "ai"]
        final_response = ai_messages[-1] if ai_messages else HumanMessage(content="æ™ºèƒ½ä»£ç†å¤„ç†å®Œæˆï¼Œä½†æ²¡æœ‰ç”Ÿæˆå“åº”ã€‚")

        # æ„å»ºè¿”å›ç»“æœ
        response_data = {
            "response": {"messages": [final_response]},
            "agent_used": "intelligent",
            "processing_time": processing_time,
            "total_time": processing_time,
            # "tool_calls_summary": tool_calls_info,
            "artifacts": artifacts,
            "processed_artifacts": processed_artifacts,
            "uni_messages": message_segments,
            "memory_info": {
                "max_messages": max_messages,
                "current_messages": len(response.get("messages", [])),
                "memory_trimmed": len(messages) > max_messages,
            },
        }

        return response_data

    except Exception as e:
        total_time = time.time() - start_time
        logger.error(f"ğŸ’¥ æ™ºèƒ½ä»£ç†ç³»ç»Ÿæ‰§è¡Œå¤±è´¥: {str(e)}")

        return {
            "response": {"messages": [HumanMessage(content=f"ç³»ç»Ÿå¤„ç†å‡ºç°é”™è¯¯: {str(e)}")]},
            "agent_used": "error",
            "processing_time": total_time,
            "total_time": total_time,
            "tool_calls_summary": {"total_tool_calls": 0, "tools_used": [], "detailed_calls": []},
            "artifacts": [],
            "processed_artifacts": [],
            "uni_messages": [],
            "error": str(e),
        }


# ä¿æŒå‘åå…¼å®¹çš„å‡½æ•°åˆ«å
async def react_agent(messages):
    """å‘åå…¼å®¹çš„å‡½æ•°åˆ«å"""
    return await intelligent_agent(messages)
