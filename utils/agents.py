import time
import uuid
import zoneinfo
from datetime import datetime
from typing import Any

from deepagents import create_deep_agent
from deepagents.backends import FilesystemBackend
from langchain.agents import AgentState, create_agent
from langchain.agents.middleware import PIIMiddleware
from langchain.messages import AIMessage
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver
from nonebot import logger

from tools import agent_tools
from utils.configs import EnvConfig
from utils.subagents import fact_check_subagent


async def assistant_agent(
    system_prompt: str = "",
    user_prompt: str = "",
    use_model: str = EnvConfig.BASIC_MODEL,
    tools=None,
    response_format=None,
    middleware=None,
) -> Any:
    if not system_prompt:
        try:
            with open("prompts/system_prompt.txt", encoding="utf-8") as f:
                system_prompt = f.read()
        except FileNotFoundError:
            logger.warning("âŒ æœªæ‰¾åˆ° system prompt æ–‡ä»¶: prompts/system_prompt.txt")
            system_prompt = "You are a helpful assistant."
    model = ChatOpenAI(
        api_key=EnvConfig.OPENAI_API_KEY,
        base_url=EnvConfig.OPENAI_BASE_URL,
        model=use_model,
        streaming=False,
        max_retries=2,
        timeout=30,
    )
    agent = create_agent(
        model=model,
        tools=tools,
        system_prompt=system_prompt,
        middleware=middleware or [],
        response_format=response_format,
        debug=EnvConfig.AGENT_DEBUG_MODE,
    )
    result = await agent.ainvoke({"messages": [{"role": "user", "content": user_prompt}]})
    if response_format:
        return result["structured_response"]
    content = ""
    for msg in result["messages"]:
        if msg.type == "ai" and not isinstance(msg.content, list):
            content += msg.content
    return content


class CustomAgentState(AgentState):
    user_id: str


class FrontierCognitive:
    def __init__(self):
        self.tools = agent_tools.all_tools
        self.subagents: list = [fact_check_subagent]
        self.checkpoint = InMemorySaver()
        self.backend = FilesystemBackend(root_dir="./cache/deep_agents")

    @staticmethod
    def load_system_prompt():
        """ä»å¤–éƒ¨æ–‡ä»¶åŠ è½½ system prompt"""
        try:
            with open("prompts/system_prompt.txt", encoding="utf-8") as f:
                system_prompt = f.read()
                system_prompt = system_prompt.format(
                    name=EnvConfig.BOT_NAME,
                    current_time=datetime.now()
                    .astimezone(zoneinfo.ZoneInfo("Asia/Shanghai"))
                    .strftime("%Y-%m-%d %H:%M:%S"),
                )
                return system_prompt
        except FileNotFoundError:
            logger.error("âŒ æœªæ‰¾åˆ° system prompt æ–‡ä»¶: prompts/system_prompt.txt")
            return f"You are {EnvConfig.BOT_NAME}, a helpful assistant. [é…ç½®é”™è¯¯: system promptæ–‡ä»¶ç¼ºå¤±]"
        except PermissionError as e:
            logger.error(f"âŒ æ— æƒé™è¯»å– system prompt æ–‡ä»¶: {e}")
            return f"You are {EnvConfig.BOT_NAME}, a helpful assistant. [é…ç½®é”™è¯¯: æ— è¯»å–æƒé™]"
        except UnicodeDecodeError as e:
            logger.error(f"âŒ system prompt æ–‡ä»¶ç¼–ç é”™è¯¯: {e}")
            return f"You are {EnvConfig.BOT_NAME}, a helpful assistant. [é…ç½®é”™è¯¯: æ–‡ä»¶ç¼–ç æ— æ•ˆ]"
        except KeyError as e:
            logger.error(f"âŒ system prompt æ¨¡æ¿å˜é‡ç¼ºå¤±: {e}")
            return f"You are {EnvConfig.BOT_NAME}, a helpful assistant. [é…ç½®é”™è¯¯: æ¨¡æ¿å˜é‡ç¼ºå¤±]"

    @staticmethod
    async def extract_uni_messages(response):
        """ç›´æ¥ä»å“åº”ä¸­æå– UniMessage å¯¹è±¡"""
        if not response or not isinstance(response, dict):
            logger.warning("âš ï¸ extract_uni_messages: response ä¸ºç©ºæˆ–ä¸æ˜¯å­—å…¸ç±»å‹")
            return []

        uni_messages = []
        for message in response.get("messages", []):
            if getattr(message, "type", None) == "tool" and getattr(message, "artifact", None) is not None:
                tool_name = getattr(message, "name", "unknown")
                uni_messages.append(message.artifact)
                logger.info(f"ğŸ“¤ æå– UniMessage: {tool_name} - ç±»å‹: {type(message.artifact)}")

        logger.info(f"ğŸ“¨ æ€»å…±æå–åˆ° {len(uni_messages)} ä¸ª UniMessage")
        return uni_messages

    async def chat_agent(self, messages, user_id, user_name, capability: str = "minimal"):
        model = ChatOpenAI(
            api_key=EnvConfig.OPENAI_API_KEY,
            base_url=EnvConfig.OPENAI_BASE_URL,
            model=EnvConfig.ADVAN_MODEL,
            streaming=False,
            reasoning_effort=capability,
            verbosity="low",
            max_retries=2,
            timeout=60,
            use_responses_api=None,
        )
        agent = create_deep_agent(
            model=model,
            system_prompt=self.load_system_prompt(),
            tools=self.tools,
            middleware=[
                PIIMiddleware(
                    "api_key",
                    detector=r"sk-[a-zA-Z0-9]{32}",
                    strategy="block",
                )
            ],
            skills=None,
            backend=self.backend,
            subagents=self.subagents,
            checkpointer=self.checkpoint,
            context_schema=CustomAgentState,
            debug=EnvConfig.AGENT_DEBUG_MODE,
        )
        start_time = time.time()
        logger.info(f"Agentçƒ§çƒ¤ä¸­~ğŸ– æ€è€ƒç­‰çº§: {capability} ç”¨æˆ·: {user_name} (ID: {user_id})")
        config: RunnableConfig = {
            "configurable": {
                "thread_id": uuid.uuid5(namespace=uuid.NAMESPACE_OID, name=user_id),
            }
        }
        try:
            response = await agent.ainvoke({"messages": messages, "user_id": user_id}, config=config)
        except TimeoutError as e:
            logger.error(f"âŒ Agentè¯·æ±‚è¶…æ—¶ ç”¨æˆ·{user_id}: {e}")
            return {
                "response": {"messages": [AIMessage("â±ï¸ è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚")]},
                "total_time": time.time() - start_time,
                "uni_messages": [],
            }
        except (ConnectionError, OSError) as e:
            logger.error(f"âŒ Agentç½‘ç»œé”™è¯¯ ç”¨æˆ·{user_id}: {e}")
            return {
                "response": {"messages": [AIMessage("ğŸŒ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚")]},
                "total_time": time.time() - start_time,
                "uni_messages": [],
            }
        except (KeyError, AttributeError, ValueError) as e:
            logger.error(f"âŒ Agenté…ç½®/æ•°æ®é”™è¯¯ ç”¨æˆ·{user_id}: {type(e).__name__}: {e}")
            logger.exception("å®Œæ•´é”™è¯¯å †æ ˆ:")
            return {
                "response": {"messages": [AIMessage("âš™ï¸ ç³»ç»Ÿé…ç½®é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")]},
                "total_time": time.time() - start_time,
                "uni_messages": [],
            }
        except Exception as e:
            # å…¶ä»–æ„å¤–é”™è¯¯ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
            logger.error(f"âŒ Agentæ‰§è¡Œå‡ºç°æ„å¤–é”™è¯¯ ç”¨æˆ·{user_id}: {type(e).__name__}: {e}")
            logger.exception("å®Œæ•´é”™è¯¯å †æ ˆ:")
            return {
                "response": {"messages": [AIMessage("ğŸ’¥ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")]},
                "total_time": time.time() - start_time,
                "uni_messages": [],
            }

        uni_messages = await FrontierCognitive.extract_uni_messages(response)
        ai_messages = [msg for msg in response.get("messages", []) if getattr(msg, "type", None) == "ai"]
        final_response = ai_messages[-1] if ai_messages else AIMessage("æ™ºèƒ½ä»£ç†å¤„ç†å®Œæˆï¼Œä½†æ²¡æœ‰ç”Ÿæˆå“åº”ã€‚")

        processing_time = time.time() - start_time
        logger.info(f"Agentçƒ¤ç†Ÿäº†~ğŸ¥“ (è€—æ—¶: {processing_time:.2f}s)")

        return {
            "response": {"messages": [final_response]},
            "total_time": processing_time,
            "uni_messages": uni_messages,
        }
